{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from web3 import Web3 as w3\n",
    "import json\n",
    "import base64\n",
    "import psycopg2query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keys\n",
    "web3_key = # API provider\n",
    "etherscan_key = # etherscan API key\n",
    "\n",
    "# Infura HTTP endpoint Ethereum mainnet\n",
    "w3_client = w3(w3.HTTPProvider(f'https://mainnet.infura.io/v3/{web3_key}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check connection\n",
    "print(w3.isConnected)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ethereum_files/ethereum.sh]\n",
    "## Use EthereumETL to pull raw data\n",
    "\n",
    "ethereum_files/ethereumetl.sh - specify block range to pull data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [OPTIONAL]\n",
    "## Upload to ethereumetl_transactions SQL table (if using PostgreSQL DB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for blocks have already been added to avoid duplicate keys\n",
    "sql = \"\"\"\n",
    "SELECT DISTINCT block_number\n",
    "FROM ethereumetl_transactions\n",
    "\"\"\"\n",
    "psycopg2query.query(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethereumetl_df = pd.read_csv('ethereumetl_files/transactions.csv')\n",
    "ethereumetl_df['block_timestamp'] = ethereumetl_df['block_timestamp'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "\n",
    "# Insert dataframe into DB\n",
    "psycopg2query.insert_df_sql(ethereumetl_df, 'ethereumetl_transactions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [tranasction_receipts.js]\n",
    "## For more efficient extraction of transaction logs, use Asynchronous call in node.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txn_receipt = pd.read_csv('transaction_receipt.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL]\n",
    "### Upload to transaction_receipts SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psycopg2query.insert_df_sql(txn_receipt, 'transaction_receipts')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Logs for Decoding\n",
    "\n",
    "[PostgreSQL DB]\n",
    "- Filter by methodId: ethereumetl_transactions - first 10 characters = methodId\n",
    "- Map ethereumetl_transactions.hash to transaction_receipts.transaction_hash\n",
    "\n",
    "OR\n",
    "\n",
    "[PostgreSQL DB]\n",
    "- Filter by transaction_receipts.event_hash\n",
    "\n",
    "OR\n",
    "\n",
    "- Use transaction_receipt.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for decoding\n",
    "\n",
    "import traceback\n",
    "from pprint import pprint\n",
    "from eth_utils import event_abi_to_log_topic, to_hex\n",
    "from hexbytes import HexBytes\n",
    "from web3._utils.events import get_event_data\n",
    "from web3.auto import w3\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sanitize_log(log):    \n",
    "    for i, topic in enumerate(log['topics']):\n",
    "        if not isinstance(topic, HexBytes):\n",
    "            log['topics'][i] = HexBytes(topic)\n",
    "\n",
    "    if 'address' not in log:\n",
    "        log['address'] = None\n",
    "\n",
    "    if 'blockHash' not in log:\n",
    "        log['blockHash'] = None\n",
    "\n",
    "    if 'blockNumber' not in log:\n",
    "        log['blockNumber'] = None\n",
    "\n",
    "    if 'logIndex' not in log:\n",
    "        log['logIndex'] = None\n",
    "\n",
    "    if 'transactionHash' not in log:\n",
    "        log['transactionHash'] = None\n",
    "\n",
    "    if 'transactionIndex' not in log:\n",
    "        log['transactionIndex'] = None\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bytecode decoding functions (idk)\n",
    "\n",
    "def decode_tuple(t, target_field):\n",
    "    output = dict()\n",
    "    for i in range(len(t)):\n",
    "        if isinstance(t[i], (bytes, bytearray)):\n",
    "            output[target_field[i]['name']] = to_hex(t[i])\n",
    "        elif isinstance(t[i], (tuple)):\n",
    "            output[target_field[i]['name']] = decode_tuple(t[i], target_field[i]['components'])\n",
    "        else:\n",
    "            output[target_field[i]['name']] = t[i]\n",
    "    return output\n",
    "\n",
    "def decode_list_tuple(l, target_field):\n",
    "    output = l\n",
    "    for i in range(len(l)):\n",
    "        output[i] = decode_tuple(l[i], target_field)\n",
    "    return output\n",
    "\n",
    "def decode_list(l):\n",
    "    output = l\n",
    "    for i in range(len(l)):\n",
    "        if isinstance(l[i], (bytes, bytearray)):\n",
    "            output[i] = to_hex(l[i])\n",
    "        else:\n",
    "            output[i] = l[i]\n",
    "    return output\n",
    "\n",
    "def convert_to_hex(arg, target_schema):\n",
    "    \"\"\"\n",
    "    utility function to convert byte codes into human readable and json serializable data structures\n",
    "    \"\"\"\n",
    "    output = dict()\n",
    "    for k in arg:\n",
    "        if isinstance(arg[k], (bytes, bytearray)):\n",
    "            output[k] = to_hex(arg[k])\n",
    "        elif isinstance(arg[k], (list)) and len(arg[k]) > 0:\n",
    "            target = [a for a in target_schema if 'name' in a and a['name'] == k][0]\n",
    "            if target['type'] == 'tuple[]':\n",
    "                target_field = target['components']\n",
    "                output[k] = decode_list_tuple(arg[k], target_field)\n",
    "            else:\n",
    "                output[k] = decode_list(arg[k])\n",
    "        elif isinstance(arg[k], (tuple)):\n",
    "            target_field = [a['components'] for a in target_schema if 'name' in a and a['name'] == k][0]\n",
    "            output[k] = decode_tuple(arg[k], target_field)\n",
    "        else:\n",
    "            output[k] = arg[k]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def _get_abi(event_contract_address):\n",
    "    abi_url = f\"https://api.etherscan.io/api?module=contract&action=getabi&address={event_contract_address}&apikey={etherscan_key}\"\n",
    "    abi = json.loads(requests.get(abi_url).text)['result']\n",
    "    abi = json.loads(abi)\n",
    "    return abi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_topic2abi(event_contract_address):\n",
    "\n",
    "     abi = _get_abi(event_contract_address)\n",
    "\n",
    "     # Filter for only event ABIs from smart contract ABI\n",
    "     event_abi = [a for a in abi if a['type'] == 'event']\n",
    "\n",
    "     # Create key value for 32 byte log topic for given event ABI (to be matched with transaction event to capture required ABI)\n",
    "     topic2abi = {event_abi_to_log_topic(_): _ for _ in event_abi}\n",
    "     return topic2abi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_log(df): # dataframe (txn_receipt) or pull from DB using psycopg2query\n",
    "    event_data = {\n",
    "        'transaction_hash' : [],\n",
    "        'event_name' : [],\n",
    "        'event_hash' : [],\n",
    "        'event_contract_address' : [],\n",
    "        'decoded_data' : [],\n",
    "        'target_schema' : []\n",
    "    }\n",
    "\n",
    "    for i in df['logs']:\n",
    "        for n in i:\n",
    "            try:\n",
    "                # Get event contract address from downloaded logs\n",
    "                event_contract_address = n['address']\n",
    "                # Get event ABIs of smart contract address\n",
    "                topic2abi = _get_topic2abi(event_contract_address)\n",
    "                    \n",
    "                # Ensure log contains all necessary keys\n",
    "                _sanitize_log(n)\n",
    "\n",
    "                # Get the ABI of the event (first HexByte in topic) - Match topic2abi (smart contract event ABI list) with transaction event\n",
    "                event_abi_txn_event = topic2abi[n['topics'][0]]\n",
    "\n",
    "                # Get the event name\n",
    "                evt_name = event_abi_txn_event['name']                \n",
    "                    \n",
    "                # Get the event data\n",
    "                data = get_event_data(w3.codec, event_abi_txn_event, n)['args']\n",
    "                target_schema = event_abi_txn_event['inputs']\n",
    "                decoded_data = convert_to_hex(data, target_schema) # convert_to_hex from logs_decoder -- convert bytecode into human readable json serializable data structures\n",
    "\n",
    "                # Append values to dictionary\n",
    "                event_data['transaction_hash'].append(n['transactionHash'])\n",
    "                event_data['event_name'].append(evt_name)\n",
    "                event_data['event_hash'].append(w3_client.toHex(n['topics'][0]))\n",
    "                event_data['event_contract_address'].append(n['address'])\n",
    "                event_data['decoded_data'].append(decoded_data)\n",
    "                event_data['target_schema'].append(target_schema)\n",
    "\n",
    "            except:\n",
    "                # Append values to dictionary\n",
    "                event_data['transaction_hash'].append(n['transactionHash'])\n",
    "                event_data['event_name'].append('NoABI')\n",
    "                event_data['event_hash'].append(n['topics'][0])\n",
    "                event_data['event_contract_address'].append(n['address'])\n",
    "                event_data['decoded_data'].append('NoABI')\n",
    "                event_data['target_schema'].append('NoABI')\n",
    "\n",
    "\n",
    "    print(f\"Events: {len(event_data['transaction_hash'])}\")\n",
    "    return pd.DataFrame(event_data) # returns decoded event data based on logs (from df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert logs into json format\n",
    "txn_receipt['logs'] = txn_receipt['logs'].apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_logs = decode_log(txn_receipt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6 (default, Jan  8 2020, 13:42:34) \n[Clang 4.0.1 (tags/RELEASE_401/final)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "4008a0225d97e13691647f3ecadce0a2b3d6b4a00bd6336482f43ae6df836d7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
